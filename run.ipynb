{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python \n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import subprocess as sp\n",
    "import itertools\n",
    "import pandas as pd\n",
    "## CV\n",
    "import cv2\n",
    "import skvideo.io\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "## Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "## Tools\n",
    "import utils\n",
    "## Parameters\n",
    "import params ## you can modify the content of params.py\n",
    "\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Lambda, ELU, Cropping2D, BatchNormalization\n",
    "from keras.layers import Conv2D, SpatialDropout2D\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "\n",
    "## Test epoch\n",
    "epoch_ids = range(1,11)\n",
    "## Load model\n",
    "#model = utils.get_model()\n",
    "\n",
    "## Preprocess\n",
    "def img_pre_process(img):\n",
    "    \"\"\"\n",
    "    Processes the image and returns it\n",
    "    :param img: The image to be processed\n",
    "    :return: Returns the processed image\n",
    "    \"\"\"\n",
    "    ## Chop off 1/3 from the top and cut bottom 150px(which contains the head of car)\n",
    "    shape = img.shape\n",
    "    img = img[int(shape[0]/3):shape[0]-150, 0:shape[1]]\n",
    "    ## Resize the image\n",
    "    img = cv2.resize(img, (params.FLAGS.img_w, params.FLAGS.img_h), interpolation=cv2.INTER_AREA)\n",
    "    ## Return the image sized as a 4D array\n",
    "    return np.resize(img, (params.FLAGS.img_w, params.FLAGS.img_h, params.FLAGS.img_c))\n",
    "\n",
    "\n",
    "## Process video\n",
    "def extract_frames(mode='load'):\n",
    "    image_set = []\n",
    "    steerings = []\n",
    "    for epoch_id in epoch_ids:\n",
    "        print('---------- processing video for epoch {} ----------'.format(epoch_id))\n",
    "        vid_path = utils.join_dir(params.data_dir, 'epoch{:0>2}_front.mkv'.format(epoch_id))\n",
    "        csv_path = \"./epochs/epoch{:0>2d}_steering.csv\".format(epoch_id)\n",
    "        dir_name = \"./epochs/epoch{:0>2d}_front_frames\".format(epoch_id)\n",
    "        steering = pd.read_csv(csv_path)['wheel'].tolist()\n",
    "        steerings.extend(steering)\n",
    "        \n",
    "        if mode == 'save':\n",
    "            os.mkdir(dir_name)\n",
    "        frame_ids = pd.read_csv(csv_path)['ts_micro'].tolist()\n",
    "        assert os.path.isfile(vid_path)\n",
    "        frame_count = utils.frame_count(vid_path)\n",
    "        cap = skvideo.io.vreader(vid_path) #cv2.VideoCapture(vid_path)\n",
    "\n",
    "        machine_steering = []\n",
    "\n",
    "        print('performing inference...')\n",
    "        time_start = time.time()\n",
    "        frame_count = 0\n",
    "        for img in cap:\n",
    "            #assert img\n",
    "            ## you can modify here based on your model\n",
    "            #print(img.shape)\n",
    "            #cv2.imshow('frame',img)\n",
    "            img = img_pre_process(img)\n",
    "            if mode == 'save':\n",
    "                cv2.imwrite(\"{}/{}.jpg\".format(dir_name, frame_ids[frame_count-1]), img)\n",
    "            elif mode == 'load':\n",
    "                image_set.append(img)\n",
    "                #steerings.append(frame_ids[frame_count-1])\n",
    "            #deg = float(model.predict(img, batch_size=1))\n",
    "            #machine_steering.append(deg)\n",
    "            frame_count += 1\n",
    "\n",
    "        del cap\n",
    "\n",
    "        fps = frame_count / (time.time() - time_start)\n",
    "    \n",
    "        print('completed inference, total frames: {}, average fps: {} Hz'.format(frame_count, round(fps, 1)))\n",
    "    return np.array(image_set), np.array(steerings)\n",
    "    \n",
    "        #print('performing visualization...')\n",
    "        #utils.visualize(epoch_id, machine_steering, params.out_dir,\n",
    "                            #verbose=True, frame_count_limit=None)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- processing video for epoch 1 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 1500, average fps: 118.9 Hz\n",
      "---------- processing video for epoch 2 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 3900, average fps: 132.9 Hz\n",
      "---------- processing video for epoch 3 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 125.0 Hz\n",
      "---------- processing video for epoch 4 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 126.5 Hz\n",
      "---------- processing video for epoch 5 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 122.5 Hz\n",
      "---------- processing video for epoch 6 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 129.5 Hz\n",
      "---------- processing video for epoch 7 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 130.5 Hz\n",
      "---------- processing video for epoch 8 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 127.3 Hz\n",
      "---------- processing video for epoch 9 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 123.8 Hz\n",
      "---------- processing video for epoch 10 ----------\n",
      "performing inference...\n",
      "completed inference, total frames: 2700, average fps: 127.9 Hz\n",
      "(27000, 480, 270, 3) (27000,)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset():\n",
    "    image_set = []\n",
    "    steerings = []\n",
    "    for epoch_id in epoch_ids:\n",
    "        csv_path = \"./epochs/epoch{:0>2d}_steering.csv\".format(epoch_id)\n",
    "        dir_name = \"./epochs/epoch{:0>2d}_front_frames\".format(epoch_id)\n",
    "        filenames = pd.read_csv(csv_path)['ts_micro'].tolist()\n",
    "        steering = pd.read_csv(csv_path)['wheel'].tolist()\n",
    "        steerings.extend(steering)\n",
    "        #print(steerings)\n",
    "        for img in filenames:\n",
    "            image = cv2.imread(dir_name+str(img)+'.jpg')\n",
    "            #assert image\n",
    "            if image == None:\n",
    "                print(img)\n",
    "            image_set.append(image)\n",
    "    return np.array(image_set), np.array(steerings)       \n",
    "            \n",
    "            \n",
    "#extract_frames()\n",
    "X, y = extract_frames(mode='load') #load_dataset()\n",
    "print(X.shape, y.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5, -0.5, -0.5, -0.5, -0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -1.0, -1.0, -1.0, -1.5, -1.5, -1.5, -1.5, -2.0, -2.0, -2.0, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.5, -4.5, -4.5, -4.5, -4.5, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.5, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -5.0, -4.5, -4.5, -4.5, -4.5, -4.5, -4.5, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.5, -4.5, -4.5, -4.5, -5.0, -5.0, -5.0, -5.5, -5.5, -5.5, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -6.0, -5.5, -5.5, -5.5, -5.0, -5.0, -5.0, -4.5, -4.5, -4.5, -4.5, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -4.0, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.5, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -3.0, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.5, -2.0, -2.0, -2.0, -2.0, -1.5, -1.5, -1.5, -1.5, -1.5, -1.5, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, -0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 1.5, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.5, 3.5, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.0, 5.0, 5.0, 5.0, 5.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.5, 3.5, 3.5, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.5, 5.5, 5.5, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 5.5, 5.0, 5.0, 5.0, 4.5, 4.0, 4.0, 4.0, 4.0, 3.5, 3.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 2.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.5, 3.5, 3.5, 4.0, 4.0, 4.5, 4.5, 4.5, 5.0, 5.0, 5.0, 5.0, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 5.5, 6.0, 6.0, 6.0, 6.0, 5.5, 5.5, 5.5, 5.5, 5.5, 5.0, 5.0, 5.0, 5.0, 4.5, 4.5, 4.5, 4.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.5, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.5, 3.5, 3.5, 3.5, 3.5, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 3.5, 4.0, 4.0, 4.0, 4.0, 4.5, 4.5, 4.5, 4.5]\n"
     ]
    }
   ],
   "source": [
    "table = pd.read_csv('./epochs/epoch01_steering.csv')\n",
    "steering = table['wheel'].tolist()\n",
    "print(steering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (params.FLAGS.img_w, params.FLAGS.img_h, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 225.0 - 0.5, input_shape=image_shape))\n",
    "#model.add(Cropping2D(cropping=((70,25), (0,0))))\n",
    "\n",
    "model.add(Conv2D(24, (5,5), strides=(2,2), activation=None, padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "\n",
    "model.add(Conv2D(36, (5,5), strides=(2,2), activation=None, padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "\n",
    "model.add(Conv2D(48, (5,5), strides=(2,2), activation=None, padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), activation=None, padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), strides=(1,1), activation=None, padding='same', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('elu'))\n",
    "model.add(SpatialDropout2D(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(50,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21600 samples, validate on 5400 samples\n",
      "Epoch 1/1\n",
      "20096/21600 [==========================>...] - ETA: 6s - loss: 39.2441"
     ]
    }
   ],
   "source": [
    "filepath=\"./models/weights-improvement-{epoch:02d}-{val_loss:.2f}.h5\"\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "#callbacks_list = [checkpoint]\n",
    "\n",
    "history_object = model.fit(X,\n",
    "                           y,\n",
    "                           batch_size=128,\n",
    "                           validation_split=0.2,\n",
    "                           epochs=1,\n",
    "                           shuffle=True)\n",
    "                           #callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
